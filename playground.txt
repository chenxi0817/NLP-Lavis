=====  Running Parameters    =====
2025-06-11 20:57:42,395 [INFO] {
    "amp": true,
    "batch_size_eval": 64,
    "batch_size_train": 100,
    "device": "cuda",
    "dist_url": "env://",
    "distributed": false,
    "evaluate": false,
    "init_lr": 0.0001,
    "lr_sched": "linear_warmup_cosine_lr",
    "max_epoch": 10,
    "min_lr": 1e-05,
    "num_workers": 4,
    "output_dir": "output/BLIP2/Pretrain_stage1",
    "resume_ckpt_path": null,
    "seed": 42,
    "task": "image_text_pretrain",
    "train_splits": [
        "train"
    ],
    "warmup_lr": 1e-06,
    "warmup_steps": 5000,
    "weight_decay": 0.05,
    "world_size": 1
}
2025-06-11 20:57:42,395 [INFO] 
======  Dataset Attributes  ======
2025-06-11 20:57:42,395 [INFO] 
======== coco_caption =======
2025-06-11 20:57:42,396 [INFO] {
    "build_info": {
        "annotations": {
            "test": {
                "md5": "3ff34b0ef2db02d01c37399f6a2a6cd1",
                "storage": "coco/annotations/coco_karpathy_test.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_test.json"
            },
            "train": {
                "md5": "aa31ac474cf6250ebb81d18348a07ed8",
                "storage": "coco/annotations/coco_karpathy_train.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_train.json"
            },
            "val": {
                "md5": "b273847456ef5580e33713b1f7de52a0",
                "storage": "coco/annotations/coco_karpathy_val.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/datasets/coco_karpathy_val.json"
            }
        },
        "images": {
            "storage": "coco/images/"
        }
    },
    "data_type": "images",
    "dataset_card": "dataset_card/coco_caption.md",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip2_image_train"
        }
    }
}
2025-06-11 20:57:42,396 [INFO] 
======== vg_caption =======
2025-06-11 20:57:42,397 [INFO] {
    "build_info": {
        "annotations": {
            "train": {
                "storage": "vg/annotations/vg_caption.json",
                "url": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/datasets/visual_genome/vg_caption.json"
            }
        },
        "images": {
            "storage": "vg/images/"
        }
    },
    "data_type": "images",
    "text_processor": {
        "train": {
            "name": "blip_caption"
        }
    },
    "vis_processor": {
        "train": {
            "image_size": 224,
            "name": "blip_image_train"
        }
    }
}
2025-06-11 20:57:42,397 [INFO] 
======  Model Attributes  ======
2025-06-11 20:57:42,397 [INFO] {
    "arch": "blip2",
    "drop_path_rate": 0,
    "finetuned": "",
    "freeze_vit": true,
    "image_size": 224,
    "load_finetuned": false,
    "load_pretrained": false,
    "model_type": "pretrain",
    "num_query_token": 32,
    "pretrained": "https://storage.googleapis.com/sfr-vision-language-research/LAVIS/models/BLIP2/blip2_pretrained.pth",
    "use_grad_checkpoint": false,
    "vit_precision": "fp16"
}